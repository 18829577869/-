# V6 快速开始指南

## 🎯 3步启动V6

```bash
# 第一步：下载数据（5-10分钟）
python get_stock_data_v6.py

# 第二步：测试环境（< 1分钟，可选）
python test_v6.py

# 第三步：开始训练（3-4小时）
python train_v6.py
```

完成！🎉

---

## 📋 详细步骤

### 步骤0：环境准备（首次使用）

```bash
# 确认Python版本（需要3.8+）
python --version

# 安装依赖（如果还没装）
pip install stable-baselines3 gymnasium pandas numpy baostock tensorboard
```

---

### 步骤1：下载数据 ⭐

```bash
python get_stock_data_v6.py
```

**这一步做什么**：
- 下载17只股票/ETF的历史数据
- 自动分割训练集（≤2024）和测试集（>2024）
- 生成元数据文件（包含分类信息）

**需要多久**：5-10分钟（取决于网络速度）

**成功标志**：
```
下载完成
成功: 17 只
失败: 0 只

元数据已保存: stockdata/metadata_v6.csv
```

**如果失败**：
- 检查网络连接
- 重新运行
- 部分标的失败也可以继续（只要>=10只成功）

---

### 步骤2：测试环境（推荐） ✅

```bash
python test_v6.py
```

**这一步做什么**：
- 验证环境是否正常工作
- 检查差异化策略是否生效
- 测试所有动作是否可执行

**需要多久**：< 1分钟

**成功标志**：
```
所有测试完成
[结论] V6环境工作正常！

可以开始训练：
  python train_v6.py
```

**如果失败**：
- 检查是否完成步骤1
- 检查数据文件是否存在
- 查看错误信息并修复

---

### 步骤3：开始训练 🚀

```bash
python train_v6.py
```

**这一步做什么**：
- 使用PPO算法训练模型
- 训练250万步
- 自动保存检查点
- 训练完成后自动回测

**需要多久**：3-4小时（取决于CPU/GPU性能）

**训练过程中会看到**：
```
V6 组合管理版 - 训练启动
找到 17 只训练标的
找到 17 只测试标的

[V6配置] 恒生科技 | 类别:科技 | 波动:高 | 风险阈值:4 | 最大仓位:80%
[V6配置] 招商银行 | 类别:金融 | 波动:低 | 风险阈值:2 | 最大仓位:100%
...

开始训练 2,500,000 步...
| rollout/           |              |
|    ep_len_mean     | ...          |
|    ep_rew_mean     | ...          |
...
```

**训练完成后会看到**：
```
[成功] 训练完成！模型已保存：ppo_stock_v6.zip

开始分类回测...

[科技|高波动] 恒生科技
   最终净值: XX,XXX.XX 元
   总收益率: +XX.XX%
   最大回撤: XX.XX%
   ...

[整体统计]
  平均收益率: +XX%
  平均最大回撤: XX%
  平均夏普比率: X.XX
  ...

[分类统计]
  [科技] (7只)
    平均收益率: +XX%
    ...
  [金融] (3只)
    平均收益率: +XX%
    ...
```

---

## 📊 查看训练曲线（可选）

```bash
# 在新的命令行窗口
tensorboard --logdir=./logs_v6/

# 然后在浏览器打开
# http://localhost:6006
```

**重点关注**：
- `eval/mean_reward`：评估奖励（上升趋势好）
- `train/loss`：训练损失（下降趋势好）
- `train/entropy_loss`：熵（保持一定值，避免过早收敛）

---

## 🎯 预期结果

### 整体表现

```
平均收益率: 30-35%
平均最大回撤: 8-12%
平均夏普比率: 1.5-2.0
总交易次数: 50-100
风险事件: 2000-3000次
```

### 科技板块（7只）

```
预期收益: 35-50%
预期回撤: 15-25%
特点: 高风险高收益
```

### 金融板块（3只）

```
预期收益: 10-15%
预期回撤: 5-10%
特点: 低风险稳定收益
```

---

## ⚠️ 常见问题

### Q1: 找不到 `baostock` 模块

**A**:
```bash
pip install baostock
```

### Q2: 数据下载很慢或失败

**A**:
- 检查网络
- 多试几次
- 或者只使用部分标的（修改 `get_stock_data_v6.py`）

### Q3: 训练时内存不够

**A**: 在 `train_v6.py` 中减少并行环境数量
```python
# 找到这行
train_env = DummyVecEnv([make_env for _ in range(16)])

# 改为
train_env = DummyVecEnv([make_env for _ in range(8)])  # 或4
```

### Q4: 训练时间太长

**A**: 减少训练步数
```python
# 找到这行
model.learn(total_timesteps=2_500_000, ...)

# 改为
model.learn(total_timesteps=1_000_000, ...)  # 100万步，约1小时
```

### Q5: 训练中断了怎么办

**A**: 从最新检查点继续
```python
# 在 train_v6.py 开头添加
from stable_baselines3 import PPO

# 加载最新模型
model = PPO.load("./models_v6/ppo_stock_v6_XXXXXX_steps.zip", env=train_env)

# 继续训练
model.learn(total_timesteps=1_000_000, ...)
```

---

## 🚀 进阶使用

### 调整风险策略（更激进/保守）

编辑 `stock_env_v6.py`，找到 `_set_risk_params()` 函数：

```python
# 更激进的科技股策略
if volatility == '高':
    self.risk_threshold = 5      # 从4改为5（更容忍风险）
    self.max_position = 0.9      # 从0.8改为0.9（更高仓位）
    self.drawdown_tolerance = 0.30  # 从0.25改为0.30（容忍更大回撤）

# 更保守的金融股策略
elif volatility == '低':
    self.risk_threshold = 1      # 从2改为1（更谨慎）
    self.max_position = 0.8      # 从1.0改为0.8（降低仓位）
```

### 添加自己的股票

编辑 `get_stock_data_v6.py`，在 `stocks` 列表中添加：

```python
stocks = [
    # ... 原有的 ...
    
    # 你的新增
    {"code": "sh.600519", "name": "贵州茅台", "start_date": "2001-08-27", 
     "category": "消费", "volatility": "中", "style": "平衡"},
]
```

然后重新运行：
```bash
python get_stock_data_v6.py
python train_v6.py
```

### 修改标的分类

编辑 `stockdata/metadata_v6.csv`：

```csv
code,name,category,volatility,style,start_date
sh.513180,恒生科技,科技,高,激进,2020-12-16
# 把某个标的改为低波动
sh.600036,招商银行,金融,低,稳健,2002-04-09
```

保存后重新训练即可。

---

## 📈 使用训练好的模型

### 方法1：快速测试

```python
from stable_baselines3 import PPO
from stock_env_v6 import StockTradingEnv

# 加载模型
model = PPO.load("ppo_stock_v6.zip")

# 测试某个标的
env = StockTradingEnv("stockdata/test/sh.513180.恒生科技.csv")
obs, _ = env.reset()

done = False
while not done:
    action, _ = model.predict(obs, deterministic=True)
    obs, reward, done, truncated, info = env.step(action)
    env.render()

stats = env.get_stats()
print(f"\n最终收益率: {stats['total_return']:+.2f}%")
print(f"最大回撤: {stats['max_drawdown']:.2f}%")
```

### 方法2：批量评估

运行训练脚本会自动评估（已包含）。

---

## 🎯 下一步行动

### 如果结果满意 ✅

1. **延长训练**
   ```python
   # 在 train_v6.py 中
   model.learn(total_timesteps=3_000_000)  # 增加到300万步
   ```

2. **模拟盘测试**
   - 使用最近1-3个月的数据
   - 验证实时表现

3. **实盘准备**
   - 小资金测试（5-10万）
   - 严格风控
   - 逐步增加

### 如果结果不满意 ⚠️

1. **检查训练曲线**
   ```bash
   tensorboard --logdir=./logs_v6/
   ```
   - 是否收敛？
   - 是否过早停止探索？

2. **调整超参数**
   ```python
   # 在 train_v6.py 中
   learning_rate = 1e-4  # 降低学习率
   ent_coef = 0.03      # 增加探索
   ```

3. **调整奖励函数**
   - 编辑 `stock_env_v6.py` 中的 `_calculate_reward_v6()`
   - 增加盈利奖励
   - 减少惩罚力度

---

## 📚 相关文档

| 文档 | 用途 |
|------|------|
| `README_V6.md` | 完整文档 |
| `版本演进总览_V3_to_V6.md` | 版本对比 |
| `V6_文件清单.md` | 文件说明 |

---

## 🎉 总结

**最简流程**：
```bash
python get_stock_data_v6.py
python train_v6.py
```

**预计时间**：
- 数据：10分钟
- 训练：4小时
- 总计：~4小时

**预期收益**：
- 平均：30-35%
- 科技：35-50%
- 金融：10-15%

**立即开始！** 🚀

```bash
# 第一步
python get_stock_data_v6.py

# 看到 "下载完成" 后，第二步
python train_v6.py

# 然后等待3-4小时...
# 喝杯咖啡，看会儿书 ☕📖

# 完成后查看结果！
```

**祝训练顺利！** 💪🎯📈💰



