# compare_models.py - æ¨¡å‹ç‰ˆæœ¬å¯¹æ¯”è„šæœ¬
"""
å¯¹æ¯”ä¸åŒç‰ˆæœ¬æ¨¡å‹çš„æ€§èƒ½
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import font_manager
from stable_baselines3 import PPO
from stock_env_v4_final import StockTradingEnv

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'WenQuanYi Micro Hei']
plt.rcParams['axes.unicode_minus'] = False

def test_model(model_path, data_file, env_class):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹"""
    try:
        model = PPO.load(model_path)
        env = env_class(data_file)
        
        obs, _ = env.reset()
        done = False
        
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, done, truncated, _ = env.step(action)
        
        stats = env.get_stats()
        return {
            'success': True,
            'final_net_worth': stats['final_net_worth'],
            'total_return': stats['total_return'],
            'max_drawdown': stats['max_drawdown'],
            'sharpe_ratio': stats['sharpe_ratio'],
            'num_trades': stats['num_trades'],
            'win_rate': stats['win_rate'],
            'net_worth_history': env.net_worth_history
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

def compare_models():
    """å¯¹æ¯”æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹"""
    
    # å®šä¹‰è¦å¯¹æ¯”çš„æ¨¡å‹
    models = [
        {
            'name': 'V3 Final',
            'path': 'ppo_v3_no_explosion.zip',
            'env': 'stock_env_v3_final'
        },
        {
            'name': 'V4',
            'path': 'ppo_stock_model_v4.zip',
            'env': 'stock_env_v4'
        },
        {
            'name': 'V4 Final (ä¼˜åŒ–ç‰ˆ)',
            'path': 'ppo_stock_v4_final.zip',
            'env': 'stock_env_v4_final'
        }
    ]
    
    # æµ‹è¯•æ•°æ®æ–‡ä»¶
    test_files = [
        'stockdata/test/sh.600036.æ‹›å•†é“¶è¡Œ.csv',
        'stockdata/test/sh.600000.æµ¦å‘é“¶è¡Œ.csv',
        'stockdata/test/159966.SZ.åˆ›è“ç­¹.csv'
    ]
    
    # è¿‡æ»¤å­˜åœ¨çš„æ–‡ä»¶
    test_files = [f for f in test_files if os.path.exists(f)]
    
    if len(test_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•æ•°æ®ï¼")
        return
    
    print("="*70)
    print("ğŸ“Š æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print("="*70)
    
    results = {model['name']: [] for model in models}
    
    for test_file in test_files:
        stock_name = test_file.split('/')[-1].replace('.csv', '')
        print(f"\næµ‹è¯•è‚¡ç¥¨: {stock_name}")
        print("-"*70)
        
        for model_info in models:
            model_name = model_info['name']
            model_path = model_info['path']
            env_name = model_info['env']
            
            if not os.path.exists(model_path):
                print(f"  âš ï¸ {model_name}: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨")
                results[model_name].append(None)
                continue
            
            # åŠ¨æ€å¯¼å…¥å¯¹åº”çš„ç¯å¢ƒ
            try:
                if env_name == 'stock_env_v3_final':
                    from stock_env_v3_final import StockTradingEnv as EnvClass
                elif env_name == 'stock_env_v4':
                    from stock_env_v4 import StockTradingEnv as EnvClass
                else:  # stock_env_v4_final
                    from stock_env_v4_final import StockTradingEnv as EnvClass
                
                result = test_model(model_path, test_file, EnvClass)
                
                if result['success']:
                    results[model_name].append(result)
                    print(f"  âœ“ {model_name}: æ”¶ç›Š {result['total_return']:+.2f}% | "
                          f"å›æ’¤ {result['max_drawdown']:.2f}% | "
                          f"å¤æ™® {result['sharpe_ratio']:.2f}")
                else:
                    results[model_name].append(None)
                    print(f"  âœ— {model_name}: {result['error']}")
                    
            except Exception as e:
                results[model_name].append(None)
                print(f"  âœ— {model_name}: {e}")
    
    # æ±‡æ€»ç»Ÿè®¡
    print("\n" + "="*70)
    print("ğŸ“ˆ å¹³å‡æ€§èƒ½å¯¹æ¯”")
    print("="*70)
    
    summary = []
    for model_name, model_results in results.items():
        valid_results = [r for r in model_results if r is not None]
        
        if len(valid_results) > 0:
            avg_return = np.mean([r['total_return'] for r in valid_results])
            avg_drawdown = np.mean([r['max_drawdown'] for r in valid_results])
            avg_sharpe = np.mean([r['sharpe_ratio'] for r in valid_results])
            avg_win_rate = np.mean([r['win_rate'] for r in valid_results])
            
            summary.append({
                'model': model_name,
                'avg_return': avg_return,
                'avg_drawdown': avg_drawdown,
                'avg_sharpe': avg_sharpe,
                'avg_win_rate': avg_win_rate,
                'test_count': len(valid_results)
            })
            
            print(f"\n{model_name}:")
            print(f"  å¹³å‡æ”¶ç›Šç‡: {avg_return:+.2f}%")
            print(f"  å¹³å‡æœ€å¤§å›æ’¤: {avg_drawdown:.2f}%")
            print(f"  å¹³å‡å¤æ™®æ¯”ç‡: {avg_sharpe:.2f}")
            print(f"  å¹³å‡èƒœç‡: {avg_win_rate:.2f}%")
            print(f"  æµ‹è¯•æ•°é‡: {len(valid_results)}/{len(model_results)}")
    
    # ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨
    if len(summary) > 0:
        plot_comparison(summary)
    
    print("\nâœ… å¯¹æ¯”å®Œæˆï¼")

def plot_comparison(summary):
    """ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨"""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    models = [s['model'] for s in summary]
    returns = [s['avg_return'] for s in summary]
    drawdowns = [s['avg_drawdown'] for s in summary]
    sharpes = [s['avg_sharpe'] for s in summary]
    win_rates = [s['avg_win_rate'] for s in summary]
    
    colors = ['#3498db', '#e74c3c', '#2ecc71']
    
    # 1. å¹³å‡æ”¶ç›Šç‡
    ax1 = axes[0, 0]
    bars1 = ax1.bar(models, returns, color=colors[:len(models)])
    ax1.set_title('å¹³å‡æ”¶ç›Šç‡å¯¹æ¯”', fontsize=12, fontweight='bold')
    ax1.set_ylabel('æ”¶ç›Šç‡ (%)')
    ax1.axhline(y=0, color='gray', linestyle='--', linewidth=1)
    ax1.grid(True, alpha=0.3, axis='y')
    for bar, val in zip(bars1, returns):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:+.1f}%', ha='center', va='bottom' if val > 0 else 'top')
    
    # 2. å¹³å‡æœ€å¤§å›æ’¤
    ax2 = axes[0, 1]
    bars2 = ax2.bar(models, drawdowns, color=colors[:len(models)])
    ax2.set_title('å¹³å‡æœ€å¤§å›æ’¤å¯¹æ¯”', fontsize=12, fontweight='bold')
    ax2.set_ylabel('å›æ’¤ (%)')
    ax2.grid(True, alpha=0.3, axis='y')
    for bar, val in zip(bars2, drawdowns):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.1f}%', ha='center', va='bottom')
    
    # 3. å¤æ™®æ¯”ç‡
    ax3 = axes[1, 0]
    bars3 = ax3.bar(models, sharpes, color=colors[:len(models)])
    ax3.set_title('å¤æ™®æ¯”ç‡å¯¹æ¯”', fontsize=12, fontweight='bold')
    ax3.set_ylabel('å¤æ™®æ¯”ç‡')
    ax3.axhline(y=0, color='gray', linestyle='--', linewidth=1)
    ax3.axhline(y=1, color='orange', linestyle='--', linewidth=1, alpha=0.5)
    ax3.grid(True, alpha=0.3, axis='y')
    for bar, val in zip(bars3, sharpes):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.2f}', ha='center', va='bottom' if val > 0 else 'top')
    
    # 4. èƒœç‡
    ax4 = axes[1, 1]
    bars4 = ax4.bar(models, win_rates, color=colors[:len(models)])
    ax4.set_title('å¹³å‡èƒœç‡å¯¹æ¯”', fontsize=12, fontweight='bold')
    ax4.set_ylabel('èƒœç‡ (%)')
    ax4.axhline(y=50, color='gray', linestyle='--', linewidth=1)
    ax4.grid(True, alpha=0.3, axis='y')
    for bar, val in zip(bars4, win_rates):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.1f}%', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')
    print("\nğŸ“Š å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: model_comparison.png")

if __name__ == '__main__':
    compare_models()



